# Transformers learn in-context by gradient descent
Notebooks for easy replication of the results in the paper **Transformers learn in-context by gradient descent**.

As the naming suggests, the three notebooks can be used to reproduce the results for the

1. specific token construction where we concatenate in- and outputs.
2. usual token construction where we provide in- and outputs in neighbouring tokens.
3. experiments on non-linear regression tasks.
